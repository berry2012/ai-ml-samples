{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cb7681-176b-42fc-a1d0-46cb92ae4f2c",
   "metadata": {},
   "source": [
    "# Multimodal Algorithm for Misinformation Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35682a-8da2-46be-a12e-bc33e836bf4b",
   "metadata": {},
   "source": [
    "Implementing a proof of concept (PoC) for a multimodal algorithm for misinformation detection requires integrating multiple data sources (text, images, videos, etc.) and leveraging AI/ML techniques to analyze and classify misinformation. \n",
    "\n",
    "Text Data: https://huggingface.co/datasets/ErfanMoosaviMonazzah/fake-news-detection-dataset-English\n",
    "\n",
    "Image Data: \n",
    "\n",
    "Video Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48a475-4a49-431c-9576-2ad628805eba",
   "metadata": {},
   "source": [
    "**Install dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e5485-2dd4-41fb-bb0f-6da2931c984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python-headless\n",
    "#%conda install -c numba numba\n",
    "#%conda install -c conda-forge librosa\n",
    "#%pip install -U datasets huggingface_hub fsspec\n",
    "#%pip install torchaudio\n",
    "#%pip install librosa\n",
    "# pip uninstall torch torchvision transformers\n",
    "# pip install torch torchvision\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c14576-4d36-49f2-a2aa-84fe1eda8be5",
   "metadata": {},
   "source": [
    "# 1. Data Collection & Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c39ac0-f9b3-4b04-9f21-f1782bef5eb4",
   "metadata": {},
   "source": [
    "## Text Analysis: Using transformer model (BERT) for fake news detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce40b4-860e-48ce-9e80-9ba525888e51",
   "metadata": {},
   "source": [
    "### Explore FakeNewsNet Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed63fc-eef5-4198-a6ac-9279773c27ce",
   "metadata": {},
   "source": [
    "**The FakeNewsNet dataset includes fake and real news articles along with metadata such as user engagement and network interactions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be67a8-b7ce-41ec-90bd-0ef33eb57645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load FakeNewsNet dataset from Hugging Face\n",
    "dataset = load_dataset(\"ErfanMoosaviMonazzah/fake-news-detection-dataset-English\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Display sample\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nFakeNewsNet dataset explored successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f71ce-6afc-4c97-8e48-beb1c7537837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of the number of words in the train data 'title'\n",
    "import matplotlib.pyplot as plt\n",
    "seq_len = [len(i.split()) for i in df['title']]\n",
    "pd.Series(seq_len).hist(bins = 40,color='firebrick')\n",
    "plt.xlabel('Number of words')\n",
    "plt.ylabel('Number of texts')\n",
    "plt.title('Histogram of Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392695f-ccc0-4efc-884a-a7376502f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data imbalance\n",
    "label_size = df.groupby('label').size()\n",
    "print(label_size)\n",
    "\n",
    "plt.pie(label_size, explode=[0.1,0.1], colors=['firebrick','blue'], startangle=90,labels=['Fake News', 'Real News'], shadow=True, autopct='%1.1f%%')\n",
    "plt.title('Data Imbalance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362ca7e-3728-4976-b9d7-ae470ade8e10",
   "metadata": {},
   "source": [
    "## Text Data Preprocessing (BERT Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef1d27-2fdc-4450-862f-f7d314cbbb27",
   "metadata": {},
   "source": [
    "### How This Works\n",
    "\n",
    "✔ Loads FakeNewsNet dataset\n",
    "\n",
    "✔ Preprocesses text with BERT tokenization\n",
    "\n",
    "✔ Creates PyTorch Dataloader for batch processing\n",
    "\n",
    "✔ Fine-tunes BERT for Fake News classification\n",
    "\n",
    "✔ Trains & evaluates the model with accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8140cd9-53b6-4a59-b47a-05603fd9f029",
   "metadata": {},
   "source": [
    "This imports BERT's tokenizer from the Hugging Face transformers library\n",
    "\n",
    "bert-base-uncased is a pre-trained BERT model that treats text as lowercase (e.g., \"Hello\" and \"hello\" are treated the same)\n",
    "\n",
    "Tokenize a sample data to what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5020a0-db7f-4ab3-be65-af702448ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    \"\"\"\n",
    "    Tokenize a batch of texts with BERT.\n",
    "    \n",
    "    Args:\n",
    "    texts (list of str): List of text samples to tokenize.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing input_ids, attention_mask, and token_type_ids.\n",
    "    \"\"\"\n",
    "    encoded_inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",  # Pad to max_length for batch consistency\n",
    "        truncation=True,       # Truncate texts longer than 20 tokens\n",
    "        max_length=15,        # BERT max token limit\n",
    "        return_tensors=\"pt\"    # Return PyTorch tensors\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": encoded_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": encoded_inputs[\"attention_mask\"],\n",
    "        \"token_type_ids\": encoded_inputs[\"token_type_ids\"]\n",
    "    }\n",
    "\n",
    "# Example usage with a batch of texts\n",
    "sample_text = [\"Fake news detection using multimodal learning.\",\n",
    "               \"Using Bert.\"]\n",
    "\n",
    "# Tokenize and print results\n",
    "tokenized_output = preprocess_text(sample_text)\n",
    "print(tokenized_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4780fea-8a86-49c5-ad9b-f550dd198613",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ccfdb-4fba-4734-be5c-dd603b0e57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"ErfanMoosaviMonazzah/fake-news-detection-dataset-English\")\n",
    "\n",
    "# Select all the rows in training dataset\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "val_data = dataset[\"validation\"]\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=20)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "test_data = test_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert labels to tensor format\n",
    "def format_dataset(data):\n",
    "    return data.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_data = format_dataset(train_data)\n",
    "test_data = format_dataset(test_data)\n",
    "val_data = format_dataset(val_data)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8)\n",
    "val_dataloader = DataLoader(val_data, batch_size=8)\n",
    "\n",
    "# Load BERT model with classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "num_training_steps = len(train_dataloader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Define the loss functions\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Save model directory\n",
    "best_model_path = \"best_bert_fake_news_detector\"\n",
    "os.makedirs(best_model_path, exist_ok=True)\n",
    "\n",
    "# Initialize best accuracy tracking\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(dataloader, split_name):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Evaluating on {split_name}\"):\n",
    "            batch = {\n",
    "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                \"labels\": batch[\"label\"].to(device),  # Rename 'label' to 'labels'\n",
    "            }\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"📊 {split_name} Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Training loop with best model saving\n",
    "\n",
    "num_epochs = 3\n",
    "print(\"\\n🚀 Training Started...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        batch = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            \"labels\": batch[\"label\"].to(device),  # Rename 'label' to 'labels'\n",
    "        }\n",
    "        \n",
    "        outputs = model(**batch)  # No error now\n",
    "        loss = criterion(outputs.logits, batch[\"labels\"])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Evaluate after each epoch\n",
    "    val_accuracy = evaluate_model(val_dataloader, \"Validation\")\n",
    "\n",
    "    # Save the model if validation accuracy improves\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.save_pretrained(best_model_path)\n",
    "        tokenizer.save_pretrained(best_model_path)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_accuracy': best_val_accuracy\n",
    "        }, os.path.join(best_model_path, \"best_text_model.pth\"))\n",
    "        print(f\"✅ Best model saved with Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"✅ Training Completed!\")\n",
    "\n",
    "\n",
    "# Load the best model for evaluation\n",
    "print(\"\\n🔄 Loading the best model...\")\n",
    "best_model = BertForSequenceClassification.from_pretrained(best_model_path)\n",
    "best_tokenizer = BertTokenizer.from_pretrained(best_model_path)\n",
    "best_model.to(device)\n",
    "print(\"✅ Best model loaded successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1939b2-9a5e-42bd-abe3-e5fe662f03de",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470ebb0-16cc-4b87-988a-163cad83d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "evaluate_model(test_dataloader, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd76d0-f6a4-4fb8-b6c1-1fdabe9f6a66",
   "metadata": {},
   "source": [
    "**After training, you can load the model and make predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b8ca5-8d6b-4295-b6fb-3f5b55f6d3f1",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11db1c-2ba0-470c-8240-1d5b06c558b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def classification_report_test(model, dataloader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating on Test Set\"):\n",
    "            batch = {\n",
    "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                \"labels\": batch[\"label\"].to(device),  # Ensure correct label key\n",
    "            }\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "            all_preds.extend(predictions.cpu().numpy())  # Convert to NumPy for sklearn\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"Real\", \"Fake\"])\n",
    "    print(\"\\n📊 Classification Report on Test Set:\\n\")\n",
    "    print(report)\n",
    "\n",
    "classification_report_test(model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ec274-6fe7-48a0-a559-b38bca9c2a6c",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* Precision: How many of the predicted \"Fake\" news are actually fake?\n",
    "\n",
    "* Recall: How many actual \"Fake\" news were correctly identified?\n",
    "\n",
    "* F1-score: The harmonic mean of precision & recall.\n",
    "\n",
    "* Support: Number of test samples in each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748bfa1-b7c9-4db2-9712-53be60ed7356",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3fa23-3ae7-4af3-bd54-5e82a0265c6b",
   "metadata": {},
   "source": [
    "# Image Analysis: Using ViTs for detecting manipulated images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1854b-18c1-47b3-b43f-264b57701abf",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c921c9d-0b35-464a-b4c7-ad401d2dd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import json\n",
    "import psutil\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "\n",
    "# # First, create a directory to save models if it doesn't exist\n",
    "# save_dir = 'image_model_checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f39970-a420-4638-b2e0-5cbdda659a1a",
   "metadata": {},
   "source": [
    "### Prepare to Load the Image Manipulation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2f7b5-f184-48b4-8c49-143e6c76456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image processor\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "# Disable PIL's size limit\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Monitor memory usage\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "def preprocess_image(image, max_size=1024):\n",
    "    \"\"\"Process a single image with size limiting\"\"\"\n",
    "    try:\n",
    "        # Ensure image is in RGB format\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Get image dimensions\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Resize if the image is too large\n",
    "        if width > max_size or height > max_size:\n",
    "            aspect_ratio = width / height\n",
    "            if width > height:\n",
    "                new_width = max_size\n",
    "                new_height = int(max_size / aspect_ratio)\n",
    "            else:\n",
    "                new_height = max_size\n",
    "                new_width = int(max_size * aspect_ratio)\n",
    "            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Process the image\n",
    "        processed = image_processor(image, return_tensors=\"pt\")\n",
    "        return processed.pixel_values[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "class StreamingImageDataset(Dataset):\n",
    "    def __init__(self, dataset_split, buffer_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with a buffer to store samples\n",
    "        Args:\n",
    "            dataset_split: The dataset split (train or test)\n",
    "            buffer_size: Number of samples to keep in memory\n",
    "        \"\"\"\n",
    "        self.dataset = dataset_split\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "        self.current_index = 0\n",
    "        \n",
    "        # Fill initial buffer\n",
    "        self._fill_buffer()\n",
    "    \n",
    "    def _fill_buffer(self):\n",
    "        \"\"\"Fill the buffer with processed images\"\"\"\n",
    "        print(\"Filling data buffer...\")\n",
    "        self.buffer = []\n",
    "        \n",
    "        for i, item in enumerate(self.dataset.take(self.buffer_size)):\n",
    "            processed_image = preprocess_image(item['image'])\n",
    "            if processed_image is not None:\n",
    "                self.buffer.append((processed_image, item['label']))\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Processed {i + 1} images\")\n",
    "                print_memory_usage()\n",
    "        \n",
    "        print(f\"Buffer filled with {len(self.buffer)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.buffer[idx]\n",
    "\n",
    "def create_data_loaders(batch_size=32, buffer_size=1000):\n",
    "    \"\"\"Create data loaders with streaming datasets\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset\n",
    "        dataset = load_dataset(\"date3k2/raw_real_fake_images\", streaming=True)\n",
    "        \n",
    "        # Create streaming datasets\n",
    "        train_dataset = StreamingImageDataset(dataset['train'], buffer_size=buffer_size)\n",
    "        test_dataset = StreamingImageDataset(dataset['test'], buffer_size=buffer_size)\n",
    "        \n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating data loaders: {e}\")\n",
    "        raise\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=3, save_dir='image_model_results'):\n",
    "    \"\"\"Train the model with checkpointing and monitoring\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "            print_memory_usage()  # Monitor memory usage\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(pixel_values=images)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'accuracy': f'{correct/total:.4f}'\n",
    "            })\n",
    "            \n",
    "            # Clear some memory\n",
    "            del outputs, loss\n",
    "            gc.collect()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_accuracy = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Save checkpoint if best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': test_accuracy,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(save_dir, 'best_image_model.pth'))\n",
    "            print(f\"✅ New best model saved with accuracy: {test_accuracy:.4f}\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Evaluating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(pixel_values=images)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Clear some memory\n",
    "            del outputs\n",
    "            gc.collect()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "    \n",
    "print(\"✅ Prepared to Load Data and Train Model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07773284-4d78-4730-9100-e2118c62fa9b",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18359437-9731-4fc7-947b-9e1124c2941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000  # Adjust based on your available memory\n",
    "    NUM_EPOCHS = 3\n",
    "    SAVE_DIR = 'image_model_results'\n",
    "    \n",
    "    try:\n",
    "        # Create data loaders\n",
    "        print(\"Initializing data loaders...\")\n",
    "        train_loader, test_loader = create_data_loaders(\n",
    "            batch_size=BATCH_SIZE,\n",
    "            buffer_size=BUFFER_SIZE\n",
    "        )\n",
    "        print(\"✅ DataLoaders Ready!\")\n",
    "        \n",
    "        # Initialize model\n",
    "        print(\"Loading Pretrained Vision Transformer (ViT) Model...\")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            \"google/vit-base-patch16-224\",\n",
    "            num_labels=2,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        model.to(device)\n",
    "        print(\"✅ Vision Transformer (ViT) Model Loaded!\")\n",
    "        \n",
    "        # Train model\n",
    "        train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            save_dir=SAVE_DIR\n",
    "        )\n",
    "        \n",
    "        # Final evaluation\n",
    "        print(\"\\nPerforming final evaluation...\")\n",
    "        final_accuracy = evaluate_model(model, test_loader, device)\n",
    "        print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613367d-b476-439c-8725-1a28b4b5cb14",
   "metadata": {},
   "source": [
    "**Evaluating Learning Curve Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34d5fc-fe5f-48bc-a67c-a17d57a2db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, learning_rates, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train and evaluate model across different learning rates\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\nTraining with learning rate: {lr}\")\n",
    "        \n",
    "        # Reset model or create new instance\n",
    "        model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "        \n",
    "        # Initialize optimizer and criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass - note we need to access .logits\n",
    "                outputs = model(images).logits\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            # Print epoch statistics\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate and store results\n",
    "        print(f\"\\nEvaluating model with learning rate {lr}\")\n",
    "        results[lr] = evaluate_model_performance(model, test_loader, device)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_learning_rate_comparison(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_model_performance(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with comprehensive metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_pred_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model outputs - note the .logits attribute\n",
    "            outputs = model(images).logits\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            pred_probs = torch.softmax(outputs, dim=1)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_probs.extend(pred_probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred_prob = np.array(all_pred_probs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "    ax1.set_ylabel('True Label')\n",
    "    ax1.set_xlabel('Predicted Label')\n",
    "    \n",
    "    # 2. ROC Curve\n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curve')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def plot_learning_rate_comparison(results_dict):\n",
    "    \"\"\"\n",
    "    Plot performance comparison across different learning rates\n",
    "    \n",
    "    Parameters:\n",
    "    results_dict: dictionary with learning rates as keys and performance metrics as values\n",
    "    \"\"\"\n",
    "    learning_rates = list(results_dict.keys())\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for metric in metrics:\n",
    "        values = [results_dict[lr][metric] for lr in learning_rates]\n",
    "        plt.semilogx(learning_rates, values, 'o-', label=metric.capitalize())\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Metrics vs Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize model\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            \"google/vit-base-patch16-224\",\n",
    "            num_labels=2,\n",
    "            ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define learning rates to try\n",
    "        learning_rates = [2e-5, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            learning_rates=learning_rates,\n",
    "            device=device,\n",
    "            num_epochs=3\n",
    "        )\n",
    "        \n",
    "        # Print best results\n",
    "        best_lr = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "        print(f\"\\nBest learning rate: {best_lr}\")\n",
    "        print(\"====Best model performance metrics====\")\n",
    "        print(f\"Accuracy: {results[best_lr]['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {results[best_lr]['precision']:.4f}\")\n",
    "        print(f\"Recall: {results[best_lr]['recall']:.4f}\")\n",
    "        print(f\"F1 Score: {results[best_lr]['f1']:.4f}\")\n",
    "        print(f\"AUC Score: {results[best_lr]['auc']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training and evaluation: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(\"Learning rate Evaluation Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d9bd8-a1d1-4e06-86f6-f6c7ec810d01",
   "metadata": {},
   "source": [
    "### Performance of the Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b73048-2d34-4e33-b4d9-dfd5eb71142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def collect_predictions(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Collect predictions and labels from the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_pred_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Collecting predictions\"):\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model outputs - note the .logits attribute\n",
    "            outputs = model(images).logits\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            pred_probs = torch.softmax(outputs, dim=1)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_probs.extend(pred_probs[:, 1].cpu().numpy())\n",
    "            \n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_pred_probs)\n",
    "\n",
    "def evaluate_model_performance(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with comprehensive metrics\n",
    "    \"\"\"\n",
    "    # Collect predictions\n",
    "    y_pred, y_true, y_pred_prob = collect_predictions(model, test_loader, device)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "    ax1.set_ylabel('True Label')\n",
    "    ax1.set_xlabel('Predicted Label')\n",
    "    \n",
    "    # 2. ROC Curve\n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curve')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize the model\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            \"google/vit-base-patch16-224\",\n",
    "            num_labels=2,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # Load the best saved model\n",
    "        checkpoint_path = os.path.join('image_model_results', 'best_image_model.pth')\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"\\nEvaluating model performance...\")\n",
    "        results = evaluate_model_performance(model, test_loader, device)\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(\"\\nDetailed Performance Metrics:\")\n",
    "        print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {results['precision']:.4f}\")\n",
    "        print(f\"Recall: {results['recall']:.4f}\")\n",
    "        print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "        print(f\"AUC Score: {results['auc']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea0034-d5a5-448f-9e5b-aedeb23c60c8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11716f56-1ea9-40c8-a79e-9d1ca6792372",
   "metadata": {},
   "source": [
    "# Implementation for Audio Analysis (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d1805-59e0-413b-8df7-649e0153aefd",
   "metadata": {},
   "source": [
    "### Load and Split Audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c43576-0514-47f9-94d0-ab02957f5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the entire training dataset\n",
    "full_dataset = load_dataset(\"012shin/fake-audio-detection-augmented2\", split=\"train\")\n",
    "\n",
    "print(f\"Total samples in full dataset: {len(full_dataset)}\")\n",
    "\n",
    "# Convert the dataset to a format suitable for splitting\n",
    "dataset_dict = full_dataset.to_dict()\n",
    "indices = list(range(len(full_dataset)))\n",
    "\n",
    "# Perform stratified split to maintain class distribution\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=[item for item in full_dataset['label']]\n",
    ")\n",
    "\n",
    "# Create the train and test datasets\n",
    "train_data = full_dataset.select(train_indices)\n",
    "test_data = full_dataset.select(test_indices)\n",
    "\n",
    "print(\"\\nDataset Split Results:\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Testing samples: {len(test_data)}\")\n",
    "\n",
    "# Verify class distribution in both splits\n",
    "def print_class_distribution(dataset, name=\"\"):\n",
    "    labels = [item for item in dataset['label']]\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\n{name} Split Distribution:\")\n",
    "    print(\"----------------------------\")\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        percentage = (count/len(dataset))*100\n",
    "        print(f\"Label {label}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "# Print distributions\n",
    "print_class_distribution(train_data, \"Training\")\n",
    "print_class_distribution(test_data, \"Testing\")\n",
    "\n",
    "# Optional: Save the splits for future use\n",
    "train_data.save_to_disk('train_split')\n",
    "test_data.save_to_disk('test_split')\n",
    "\n",
    "# Verify data structure\n",
    "print(\"\\nSample data structure:\")\n",
    "print(\"----------------------\")\n",
    "sample = train_data[0]\n",
    "for key, value in sample.items():\n",
    "    print(f\"{key}: {type(value)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4706556-a6cf-4e85-9655-fbc3719e7685",
   "metadata": {},
   "source": [
    "### Load Audio Dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd567d22-d9ca-4998-850f-511e85d8febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the saved splits\n",
    "train_data = load_from_disk('train_split')\n",
    "test_data = load_from_disk('test_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a23d41-535f-4d80-be44-b77f3cb56046",
   "metadata": {},
   "source": [
    "### Explore Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037c175-7fc5-44c2-90a6-2edadb871404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def analyze_class_distribution(data, split_name=\"\"):\n",
    "    # First, let's examine the structure of a single item\n",
    "    first_item = data[0]\n",
    "    print(f\"\\nFirst item label structure: {first_item['label']}\")\n",
    "    \n",
    "    # Convert dataset to a list of labels\n",
    "    # If labels are lists, take the first element\n",
    "    labels = []\n",
    "    for item in data:\n",
    "        if isinstance(item['label'], list):\n",
    "            labels.append(item['label'][0])  # Take first element if it's a list\n",
    "        else:\n",
    "            labels.append(item['label'])\n",
    "            \n",
    "    # Convert to numpy array\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Count unique labels\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    label_counts = pd.Series(counts, index=unique_labels)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total_samples = len(labels)\n",
    "    label_percentages = (label_counts / total_samples * 100).round(2)\n",
    "    \n",
    "    # Print distribution\n",
    "    print(f\"\\n{split_name} Split Distribution:\")\n",
    "    print(\"----------------------------\")\n",
    "    for label, count in label_counts.items():\n",
    "        percentage = label_percentages[label]\n",
    "        print(f\"Label {label}: {count} samples ({percentage}%)\")\n",
    "    \n",
    "    # Create pie chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(label_counts, labels=[f'Label {i}' for i in label_counts.index], \n",
    "            autopct='%1.1f%%', startangle=90,\n",
    "            colors=['lightblue', 'lightgreen'])\n",
    "    plt.title(f'Class Distribution - {split_name} Split')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    if len(label_counts) > 1:\n",
    "        imbalance_ratio = label_counts.max() / label_counts.min()\n",
    "        print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}\")\n",
    "        if imbalance_ratio > 1.5:\n",
    "            print(\"⚠️ Dataset is imbalanced (ratio > 1.5)\")\n",
    "    \n",
    "    return label_counts\n",
    "\n",
    "# Basic dataset info\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Training Samples: {len(train_data)}\")\n",
    "print(f\"Testing Samples: {len(test_data)}\")\n",
    "\n",
    "# Analyze training data\n",
    "train_distribution = analyze_class_distribution(train_data, \"Training\")\n",
    "\n",
    "# Analyze test data\n",
    "test_distribution = analyze_class_distribution(test_data, \"Test\")\n",
    "\n",
    "# Compare distributions between train and test\n",
    "plt.figure(figsize=(10, 5))\n",
    "train_props = train_distribution / len(train_data)\n",
    "test_props = test_distribution / len(test_data)\n",
    "\n",
    "bar_width = 0.35\n",
    "index = range(len(train_props))\n",
    "\n",
    "plt.bar(index, train_props, bar_width, label='Train', color='lightblue')\n",
    "plt.bar([i + bar_width for i in index], test_props, bar_width, label='Test', color='lightgreen')\n",
    "\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Class Distribution Comparison - Train vs Test')\n",
    "plt.xticks([i + bar_width/2 for i in index], [f'Label {i}' for i in train_props.index])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print sample data structure\n",
    "print(\"\\nSample Data Structure:\")\n",
    "print(\"----------------------\")\n",
    "sample_item = train_data[0]\n",
    "for key, value in sample_item.items():\n",
    "    print(f\"{key}: {type(value)} - {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624c0c1-105b-4446-8f87-57c7365e51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "# Define transformation: Convert audio to Mel Spectrogram\n",
    "mel_transform = transforms.MelSpectrogram(\n",
    "    sample_rate=16000, n_mels=64, n_fft=1024, hop_length=512\n",
    ")\n",
    "\n",
    "# Define a fixed spectrogram length (128 frames)\n",
    "FIXED_SPEC_LENGTH = 128\n",
    "\n",
    "# Function to preprocess audio\n",
    "def preprocess(example):\n",
    "    waveform = example[\"audio\"][\"array\"]  # Extract waveform\n",
    "    waveform = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0)  # Convert to float32 & add batch dimension\n",
    "    \n",
    "    mel_spec = mel_transform(waveform)  # Convert to Mel spectrogram\n",
    "\n",
    "    # Pad or truncate to fixed length\n",
    "    if mel_spec.shape[2] < FIXED_SPEC_LENGTH:\n",
    "        pad_amount = FIXED_SPEC_LENGTH - mel_spec.shape[2]\n",
    "        mel_spec = torch.nn.functional.pad(mel_spec, (0, pad_amount))  # Pad along time dimension\n",
    "    else:\n",
    "        mel_spec = mel_spec[:, :, :FIXED_SPEC_LENGTH]  # Truncate\n",
    "\n",
    "    example[\"mel_spectrogram\"] = mel_spec.squeeze(0)  # Remove batch dimension\n",
    "    return example\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data = train_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674364f-b2e2-4510-bddd-a7965dc01f7a",
   "metadata": {},
   "source": [
    "Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814136f5-48ce-4b21-8651-e016ede3bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # First convert each mel_spectrogram to a tensor\n",
    "    mel_specs = [torch.FloatTensor(item[\"mel_spectrogram\"]) for item in batch]\n",
    "    mel_specs = torch.stack(mel_specs)\n",
    "    \n",
    "    # Convert labels to class indices (not one-hot)\n",
    "    # If your labels are already one-hot encoded, convert them to indices\n",
    "    labels = [torch.argmax(torch.tensor(item[\"label\"])) if isinstance(item[\"label\"], (list, np.ndarray)) \n",
    "             else item[\"label\"] for item in batch]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return mel_specs, labels\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=8, collate_fn=collate_fn)\n",
    "\n",
    "print(\"✅ DataLoaders Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb585f6-c47a-4ff2-b6e0-10f873ed6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=64, hidden_dim=128, num_layers=2, num_classes=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Reshape for LSTM (batch, seq, feature)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Take last timestep output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de612df6-e801-4564-a06e-3c80252158f5",
   "metadata": {},
   "source": [
    "### Train & Save The Best Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36423a49-1bf5-4a98-b6b8-c965e73661b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "# Define model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop with best model saving\n",
    "num_epochs = 5\n",
    "best_accuracy = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        mel_specs, labels = batch\n",
    "        # Move tensors to device\n",
    "        mel_specs = mel_specs.to(device)\n",
    "        labels = labels.to(device)  # Now labels should be 1D tensor of indices\n",
    "\n",
    "        # Reshape if needed\n",
    "        if len(mel_specs.shape) == 2:\n",
    "            mel_specs = mel_specs.unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            outputs = model(mel_specs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {str(e)}\")\n",
    "            print(f\"mel_specs shape: {mel_specs.shape}\")\n",
    "            print(f\"labels shape: {labels.shape}\")\n",
    "            print(f\"labels dtype: {labels.dtype}\")\n",
    "            print(f\"outputs shape: {outputs.shape if 'outputs' in locals() else 'N/A'}\")\n",
    "            print(f\"outputs dtype: {outputs.dtype if 'outputs' in locals() else 'N/A'}\")\n",
    "            raise e\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': accuracy\n",
    "        }, \"best_lstm_fake_audio.pth\")\n",
    "        print(\"📁 Best model saved!\")\n",
    "\n",
    "print(\"✅ Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16219dc7-6426-4cd6-b1cd-a5060cf07662",
   "metadata": {},
   "source": [
    "### Evaluation and Performance of the Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbced7-8f54-49ff-8346-f1c2b8c9e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for mel_specs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "                # Move data to device\n",
    "                mel_specs = mel_specs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(mel_specs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                # Collect predictions and labels\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Calculate running accuracy\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "        # Calculate metrics\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Convert to numpy arrays for sklearn metrics\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n=== Model Evaluation Results ===\")\n",
    "        print(f\"📊 Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"📊 Precision: {precision:.4f}\")\n",
    "        print(f\"📊 Recall: {recall:.4f}\")\n",
    "        print(f\"📊 F1 Score: {f1:.4f}\")\n",
    "        print(\"\\n=== Confusion Matrix ===\")\n",
    "        print(cm)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': cm,\n",
    "            'predictions': all_preds,\n",
    "            'true_labels': all_labels\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {str(e)}\")\n",
    "        print(f\"Last batch shapes - mel_specs: {mel_specs.shape}, labels: {labels.shape}\")\n",
    "        raise e\n",
    "\n",
    "# Load and evaluate the model\n",
    "try:\n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(\"best_lstm_fake_audio.pth\")\n",
    "    if isinstance(checkpoint, dict):\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded model from epoch {checkpoint['epoch']} with training accuracy: {checkpoint['accuracy']:.4f}\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Make sure model is on the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Optional: Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading or evaluating model: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bbdf5-8d8d-4a35-b4fc-28e338c09449",
   "metadata": {},
   "source": [
    "# 2. Model Selection & Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34203a5-d91b-48e2-952a-c58c86d81d67",
   "metadata": {},
   "source": [
    "## Text Classification (Fake News Detection with BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875050a-7ced-45bc-aab9-092a4bacb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load trained model and tokenizer\n",
    "print(\"\\n🔄 Loading the best model...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(best_model_path)\n",
    "text_model = BertForSequenceClassification.from_pretrained(best_model_path)\n",
    "text_model.to(device)\n",
    "text_model.eval()\n",
    "print(\"✅ Best model loaded successfully!\")\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = text_model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs.logits).item()\n",
    "    return \"Fake News\" if predicted_class == 0 else \"Real News\"\n",
    "\n",
    "# Test prediction\n",
    "text = \"Can you blame her for losing her cool with Crooked Lying Hillary? Share this with all of your  undecided  friends!https://youtu.be/CCkXOix0g2Y\" # Fake News\n",
    "print(\"Prediction:\", predict(text))\n",
    "\n",
    "text = \"These people will support just about anything Obama says scary stuff!\" # Fake News\n",
    "print(\"Prediction:\", predict(text))\n",
    "\n",
    "text = \"Two people were shot dead on Friday as Kenyan police tried to disperse opposition supporters marching from an airport alongside the convoy of opposition leader Raila Odinga, a Reuters witness said.\" # Real News\n",
    "print(\"Prediction:\", predict(text))\n",
    "\n",
    "text = \"The North Korean issue should be resolved peacefully through talks, Chinese President Xi Jinping told British Prime Minister Theresa May in a telephone call, state radio said on Monday.\" # Real News\n",
    "print(\"Prediction:\", predict(text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea36753-1d01-4807-a6a6-bae571aec2f9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a1045-6897-4fda-86b9-a935d8abbc22",
   "metadata": {},
   "source": [
    "## Image Classification (ViT-based Fake Image Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cf18a-366d-4c67-8b79-d8204f9e3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "print(\"\\n🔄 Loading the best model...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize ViT model\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "# Modify the classifier for binary classification (Fake/Real)\n",
    "model.classifier = nn.Linear(model.config.hidden_size, 2)\n",
    "\n",
    "# Load the checkpoint\n",
    "save_dir = 'image_model_results'\n",
    "best_model_path = os.path.join(save_dir, 'best_image_model.pth')\n",
    "checkpoint = torch.load(best_model_path, map_location=device, weights_only=True)\n",
    "\n",
    "# Load state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_image(image_tensor, model):\n",
    "    \"\"\"\n",
    "    Make prediction on a single image\n",
    "    \"\"\"\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor).logits\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, dim=1)\n",
    "        \n",
    "        return predicted.item(), confidence.item()\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a specific image for prediction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ViT specific transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                              std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        \n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image)\n",
    "        \n",
    "        print(f\"✅ Successfully loaded image: {image_path}\")\n",
    "        return image_tensor.to(device)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test specific image\n",
    "print(\"\\n🔄 Making prediction on fake_news_image.jpeg...\")\n",
    "image_path = 'fake_news_image.jpeg'\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    # Load and preprocess the image\n",
    "    test_tensor = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    if test_tensor is not None:\n",
    "        # Make prediction\n",
    "        prediction, confidence = predict_image(test_tensor, model)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"Image: {image_path}\")\n",
    "        print(f\"Prediction: {'Fake' if prediction == 0 else 'Real'}\")\n",
    "        print(f\"Confidence: {confidence:.2%}\")\n",
    "    else:\n",
    "        print(\"❌ Failed to process the image.\")\n",
    "else:\n",
    "    print(f\"❌ Image not found: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77940afb-4b82-48f3-b14a-610a17d11cad",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9624cab-4416-45fb-a5a8-c27b2d41ff5a",
   "metadata": {},
   "source": [
    "## Multimodal Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1431ce98-3acb-4aef-86fe-9bf0981d0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded trained text model from best_bert_fake_news_detector\n",
      "✅ Loaded trained ViT model from image_model_results/best_image_model.pth\n",
      "✅ Loaded trained audio model from best_lstm_fake_audio.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalFakeNewsDetector(\n",
       "  (text_model): FakeTextDetector(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (image_model): FakeImageDetector(\n",
       "    (vit): ViTForImageClassification(\n",
       "      (vit): ViTModel(\n",
       "        (embeddings): ViTEmbeddings(\n",
       "          (patch_embeddings): ViTPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): ViTEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x ViTLayer(\n",
       "              (attention): ViTSdpaAttention(\n",
       "                (attention): ViTSdpaSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (audio_model): FakeAudioDetector(\n",
       "    (lstm): LSTM(64, 128, num_layers=2, batch_first=True)\n",
       "    (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=6, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 🔹 Load Text Model (BERT)\n",
    "class FakeTextDetector(nn.Module):\n",
    "    def __init__(self, model_path=\"best_bert_fake_news_detector\"):\n",
    "        super(FakeTextDetector, self).__init__()\n",
    "\n",
    "        # Load BERT model & tokenizer\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        # Load additional checkpoint if exists\n",
    "        checkpoint_path = os.path.join(model_path, \"best_text_model.pth\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "            self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            print(f\"✅ Loaded trained text model from {model_path}\")\n",
    "        else:\n",
    "            print(\"⚠️ Warning: Text model checkpoint not found!\")\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    # def forward(self, text_inputs):\n",
    "    #     return self.model(**text_inputs).logits\n",
    "\n",
    "    def forward(self, text_inputs):\n",
    "        # Modified forward method to handle the input dictionary\n",
    "        outputs = self.model(\n",
    "            input_ids=text_inputs['input_ids'],\n",
    "            attention_mask=text_inputs.get('attention_mask', None),\n",
    "            token_type_ids=text_inputs.get('token_type_ids', None)\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "\n",
    "# 🔹 Load Image Model (ViT)\n",
    "class FakeImageDetector(nn.Module):\n",
    "    def __init__(self, save_dir='image_model_results', model_name='best_image_model.pth'):\n",
    "        super(FakeImageDetector, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                              std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "        \n",
    "        # Initialize the ViT model\n",
    "        self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "        # Modify classifier for binary classification (Fake/Real)\n",
    "        self.vit.classifier = nn.Linear(self.vit.config.hidden_size, 2)\n",
    "        \n",
    "        # Setup model path\n",
    "        self.model_path = os.path.join(save_dir, model_name)\n",
    "        \n",
    "        # Load trained model\n",
    "        try:\n",
    "            if os.path.exists(self.model_path):\n",
    "                checkpoint = torch.load(self.model_path, map_location=device, weights_only=True)\n",
    "                state_dict = checkpoint['model_state_dict']\n",
    "                \n",
    "                print(f\"✅ Loaded trained ViT model from {self.model_path}\")    \n",
    "            else:\n",
    "                print(f\"⚠️ Warning: ViT model checkpoint not found at {self.model_path}\")\n",
    "                print(\"Model will be initialized with random weights.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading model: {str(e)}\")\n",
    "            print(\"Model will be initialized with random weights.\")\n",
    "            \n",
    "        # Move model to device\n",
    "        self.to(device)\n",
    "        self.eval()  # Set to evaluation mode by default\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass that returns logits for fusion model\n",
    "        \"\"\"\n",
    "        if len(x.shape) != 4:\n",
    "            raise ValueError(f\"Expected 4D tensor with shape [batch_size, channels, height, width], got shape {x.shape}\")\n",
    "        if x.shape[1] != 3:\n",
    "            raise ValueError(f\"Expected 3 channels, got {x.shape[1]}\")        \n",
    "        outputs = self.vit(x)\n",
    "        return outputs.logits\n",
    "\n",
    "    def predict(self, image_tensor):\n",
    "        \"\"\"\n",
    "        Standalone prediction method with confidence scores\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, dim=1)\n",
    "            return predicted.item(), confidence.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 Load Audio Model (LSTM)\n",
    "class FakeAudioDetector(nn.Module):\n",
    "    def __init__(self, audio_model_path=\"best_lstm_fake_audio.pth\", input_size=64, hidden_size=128, num_layers=2):\n",
    "        super(FakeAudioDetector, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 2)  # Ensure output has 2 neurons (Fake/Real)\n",
    "\n",
    "        # Load trained model\n",
    "        if os.path.exists(audio_model_path):\n",
    "            checkpoint = torch.load(audio_model_path, weights_only=True, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            \n",
    "            if \"model_state_dict\" in checkpoint:  # Ensure compatibility\n",
    "                self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "                print(f\"✅ Loaded trained audio model from {audio_model_path}\")\n",
    "            else:\n",
    "                self.load_state_dict(checkpoint)\n",
    "                print(\"⚠️ Warning: Model loaded without additional metadata.\")\n",
    "\n",
    "        else:\n",
    "            print(\"⚠️ Warning: Audio model checkpoint not found!\")\n",
    "\n",
    "        self.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 Multimodal Fake News Detector (Combining Text, Image & Audio)\n",
    "class MultimodalFakeNewsDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalFakeNewsDetector, self).__init__()\n",
    "\n",
    "        # Load individual models\n",
    "        self.text_model = FakeTextDetector()\n",
    "        self.image_model = FakeImageDetector()\n",
    "        self.audio_model = FakeAudioDetector()\n",
    "\n",
    "        # Fusion Layer (Combining all 3 modal features)\n",
    "        self.fc = nn.Linear(2 + 2 + 2, 2)  # Final classification\n",
    "\n",
    "    def forward(self, text_inputs, image_inputs, audio_inputs):\n",
    "        text_features = self.text_model(text_inputs)  # BERT output\n",
    "        image_features = self.image_model(image_inputs)  # ResNet output\n",
    "        audio_features = self.audio_model(audio_inputs)  # LSTM output\n",
    "\n",
    "        fused_features = torch.cat((text_features, image_features, audio_features), dim=1)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "\n",
    "# 🔹 Load the multimodal model\n",
    "multimodal_model = MultimodalFakeNewsDetector()\n",
    "multimodal_model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6a2ba-a42e-4f54-9b59-d7735b8b6371",
   "metadata": {},
   "source": [
    "# 3. Multimodal Model Training & Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b388b-a38d-4d21-bd49-2dd4c3cd5817",
   "metadata": {},
   "source": [
    "### Dataset for the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "427c97ff-2ec9-435e-9ab1-cd97ae915588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: best_bert_fake_news_detector/best_text_model.pth\n",
      "Found: image_model_results/best_image_model.pth\n",
      "Found: best_lstm_fake_audio.pth\n",
      "Inspecting audio dataset structure...\n",
      "\n",
      "Keys in first audio item: dict_keys(['id', 'audio', 'label'])\n",
      "\n",
      "Sample audio item structure: {'id': 'RUNQPNJF', 'audio': {'path': 'RUNQPNJF.ogg', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sampling_rate': 16000}, 'label': [0.0, 1.0]}\n",
      "\n",
      "Available audio keys: dict_keys(['id', 'audio', 'label'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, recall_score, f1_score, precision_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm import create_model\n",
    "import os\n",
    "\n",
    "def check_model_files():\n",
    "    model_files = [\n",
    "        'best_bert_fake_news_detector/best_text_model.pth',\n",
    "        'image_model_results/best_image_model.pth',\n",
    "        'best_lstm_fake_audio.pth'\n",
    "    ]\n",
    "    \n",
    "    for file_path in model_files:\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"Warning: {file_path} not found\")\n",
    "        else:\n",
    "            print(f\"Found: {file_path}\")\n",
    "\n",
    "# inspect model files\n",
    "check_model_files()\n",
    "\n",
    "\n",
    "def inspect_audio_dataset():\n",
    "    print(\"Inspecting audio dataset structure...\")\n",
    "    audio_data = load_dataset(\"012shin/fake-audio-detection-augmented\", split='train')\n",
    "    \n",
    "    # Get first item\n",
    "    first_item = audio_data[0]\n",
    "    print(\"\\nKeys in first audio item:\", first_item.keys())\n",
    "    print(\"\\nSample audio item structure:\", first_item)\n",
    "    \n",
    "    return first_item.keys()\n",
    "\n",
    "# inspect audio dataset\n",
    "audio_keys = inspect_audio_dataset()\n",
    "print(f\"\\nAvailable audio keys: {audio_keys}\")\n",
    "\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, split='train'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        print(f\"Loading {split} datasets...\")\n",
    "        \n",
    "        try:\n",
    "            # Load datasets from Hugging Face\n",
    "            print(\"Loading text dataset...\")\n",
    "            self.text_data = load_dataset(\"BeardedJohn/FakeNews\", split=split)\n",
    "            # self.text_data = load_dataset(\"ErfanMoosaviMonazzah/fake-news-detection-dataset-English\", split=split)\n",
    "            \n",
    "            print(\"Loading image dataset...\")\n",
    "            self.image_data = load_dataset(\"itsLeen/deepfake_vs_real_image_detection\", split=split)\n",
    "            # self.image_data = load_dataset(\"date3k2/raw_real_fake_images\", split=split)\n",
    "            \n",
    "            print(\"Loading audio dataset...\")\n",
    "            self.audio_data = load_dataset(\"012shin/fake-audio-detection-augmented\", split=split)\n",
    "            # self.audio_data = load_dataset(\"012shin/fake-audio-detection-augmented2\", split=split)\n",
    "            \n",
    "            print(\"All datasets loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading datasets: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        # Define transforms\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.text_data), len(self.image_data), len(self.audio_data))\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_batch_dimension(tensor, expected_shape):\n",
    "        \"\"\"\n",
    "        Ensures tensor has batch dimension and correct shape\n",
    "        \"\"\"\n",
    "        if tensor.dim() == len(expected_shape):\n",
    "            # Add batch dimension if missing\n",
    "            tensor = tensor.unsqueeze(0)\n",
    "        \n",
    "        current_shape = tuple(tensor.shape[1:])  # Shape without batch dimension\n",
    "        if current_shape != expected_shape:\n",
    "            raise ValueError(f\"Expected shape {expected_shape}, got {current_shape}\")\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Process text\n",
    "            text = self.text_data[idx]['text']\n",
    "            text_encoding = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Process image\n",
    "            try:\n",
    "                # Get image data\n",
    "                image_data = self.image_data[idx]['image']\n",
    "                \n",
    "                # Convert to PIL Image if it's not already\n",
    "                if isinstance(image_data, dict) and 'bytes' in image_data:\n",
    "                    image = Image.open(io.BytesIO(image_data['bytes'])).convert('RGB')\n",
    "                elif isinstance(image_data, str):\n",
    "                    # If it's a file path\n",
    "                    image = Image.open(image_data).convert('RGB')\n",
    "                elif isinstance(image_data, Image.Image):\n",
    "                    image = image_data.convert('RGB')\n",
    "                else:\n",
    "                    # If it's raw bytes\n",
    "                    image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "                \n",
    "                image_tensor = self.image_transform(image)\n",
    "                image_tensor = MultimodalDataset.ensure_batch_dimension(image_tensor, (3, 224, 224))\n",
    "                # print(\"Final image tensor shape:\", image_tensor.shape)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image at index {idx}: {str(e)}\")\n",
    "                image_tensor = torch.zeros(1, 3, 224, 224)  # Include batch dimension\n",
    "\n",
    "\n",
    "            # Process audio\n",
    "            try:\n",
    "                # Extract features from raw audio\n",
    "                audio_data = self.audio_data[idx]['audio']\n",
    "                audio_array = torch.tensor(audio_data['array'])\n",
    "                \n",
    "                # Generate features from the audio array\n",
    "                audio_features = self.extract_audio_features(audio_array)\n",
    "                \n",
    "                # Ensure correct dimensions using ensure_batch_dimension\n",
    "                audio_features = MultimodalDataset.ensure_batch_dimension(audio_features, (64,))\n",
    "                # print(\"Audio features shape:\", audio_features.shape)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing audio at index {idx}: {str(e)}\")\n",
    "                audio_features = torch.zeros(1, 64)  # Create fallback with batch dimension\n",
    "                        \n",
    "            \n",
    "            # Get labels\n",
    "            label = torch.tensor(self.text_data[idx]['label'])\n",
    "            \n",
    "            # Squeeze any extra dimensions from the text encoding\n",
    "            text_encoding = {k: v.squeeze(0) for k, v in text_encoding.items()}\n",
    "            \n",
    "            return {\n",
    "                'text': text_encoding,\n",
    "                'image': image_tensor,\n",
    "                'audio': audio_features,\n",
    "                'label': label\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def inspect_item(self, idx):\n",
    "        \"\"\"Debug method to inspect raw data at a specific index\"\"\"\n",
    "        print(\"\\nInspecting raw data at index\", idx)\n",
    "        print(\"\\nText data:\", self.text_data[idx])\n",
    "        print(\"\\nImage data:\", self.image_data[idx])\n",
    "        print(\"\\nAudio data:\", self.audio_data[idx])\n",
    "\n",
    "\n",
    "    def extract_audio_features(self, audio_array):\n",
    "        \"\"\"\n",
    "        Extract features from raw audio array\n",
    "        You can choose one of these methods or combine them\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Option 1: Simple statistical features\n",
    "            features = []\n",
    "            chunk_size = len(audio_array) // 64  # Divide audio into 64 chunks\n",
    "            \n",
    "            for i in range(0, len(audio_array), chunk_size):\n",
    "                chunk = audio_array[i:i + chunk_size]\n",
    "                features.append(chunk.mean())\n",
    "            \n",
    "            features = torch.tensor(features)\n",
    "            \n",
    "            # Ensure we have exactly 64 features\n",
    "            if len(features) < 64:\n",
    "                features = F.pad(features, (0, 64 - len(features)))\n",
    "            elif len(features) > 64:\n",
    "                features = features[:64]\n",
    "                \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature extraction: {str(e)}\")\n",
    "            return torch.zeros(64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c6ae1-92df-45cb-aa55-5a3e7ce64450",
   "metadata": {},
   "source": [
    "# 4. Evaluation & Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e240d77-2897-48ef-a22a-83031ab49a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to train model...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Enable memory efficient settings\n",
    "torch.cuda.empty_cache()\n",
    "# Set memory allocator configuration\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# Clear memory cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "class MultimodalFakeNewsDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        try:\n",
    "            print(\"Loading pre-trained models...\")\n",
    "\n",
    "            # Load individual models\n",
    "            print(\"✅ Loading BERT model...\")\n",
    "            self.text_model = FakeTextDetector()\n",
    "            print(\"✅ Loading LSTM model...\")\n",
    "            self.image_model = FakeImageDetector()\n",
    "            print(\"✅ Loading trained audio model\")\n",
    "            self.audio_model = FakeAudioDetector()\n",
    "            print(\"✅ Loaded trained models\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading models: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        self.fusion_layer = nn.Linear(2 + 2 + 2, 2)  # Final classification\n",
    "\n",
    "    def forward(self, text_input, image_input, audio_input):\n",
    "        # Get embeddings from each model\n",
    "        text_output = self.text_model(**text_input).logits\n",
    "        \n",
    "        # Clear memory after text processing if needed\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        image_output = self.image_model(image_input)\n",
    "        # Clear memory after text processing if needed\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        audio_output = self.audio_model(audio_input)\n",
    "        # Clear memory after text processing if needed\n",
    "        torch.cuda.empty_cache()        \n",
    "        \n",
    "        # Concatenate all features\n",
    "        combined = torch.cat((text_output, image_output, audio_output), dim=1)\n",
    "\n",
    "        # If intermediate outputs aren't needed anymore, delete them\n",
    "        del text_output\n",
    "        del image_output\n",
    "        del audio_output\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fusion_layer(combined)\n",
    "        return output\n",
    "\n",
    "print(\"Ready to train model...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8bb3f7-113d-4c66-b95c-83935563ccad",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63413f0-a2e9-473e-8147-2c304332bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function ready!\n"
     ]
    }
   ],
   "source": [
    "def plot_training_curves(train_losses, val_losses, learning_rates):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot learning rates\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(learning_rates)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_multimodal_model(model, train_loader, val_loader, num_epochs=3, learning_rate=0.0001):\n",
    "    print(\"Initializing training...\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Enable gradient scaler - corrected initialization\n",
    "    scaler = torch.cuda.amp.GradScaler()  # Remove device_type parameter\n",
    "\n",
    "    # Set model to use float32\n",
    "    model = model.to(device).float()\n",
    "\n",
    "    # Initialize return values    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "    accumulation_steps = 8\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    try:\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "                try:\n",
    "                    # Process in chunks with mixed precision\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        # Process each modality separately\n",
    "                        text_inputs = {k: v.to(device) for k, v in batch['text'].items()}\n",
    "                        # text_inputs = {k: v.to(device).long() for k, v in batch['text'].items()}\n",
    "\n",
    "                        # Debug print\n",
    "                        # if batch_idx == 0:\n",
    "                        #     print(\"\\nText input keys:\", text_inputs.keys())\n",
    "                        #     for k, v in text_inputs.items():\n",
    "                        #         print(f\"{k} shape:\", v.shape)\n",
    "                        \n",
    "                        text_outputs = model.text_model(text_inputs)\n",
    "                        del text_inputs\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                        # Convert inputs to float32\n",
    "                        image_inputs = batch['image'].to(device).float()\n",
    "\n",
    "                        \n",
    "                        # Remove the extra dimension (squeeze dimension 1)\n",
    "                        image_inputs = image_inputs.squeeze(1)\n",
    "                        \n",
    "                        # print(\"\\nImage tensor details:\")\n",
    "                        # print(\"Shape after squeeze:\", image_inputs.shape)\n",
    "                        # print(\"Type:\", image_inputs.dtype)\n",
    "                        # print(\"Device:\", image_inputs.device)\n",
    "                        \n",
    "                        # Verify the shape is correct\n",
    "                        if len(image_inputs.shape) != 4:\n",
    "                            raise ValueError(f\"Expected 4D tensor, got shape {image_inputs.shape}\")\n",
    "                        if image_inputs.shape[1] != 3:\n",
    "                            raise ValueError(f\"Expected 3 channels, got {image_inputs.shape[1]}\")\n",
    "                        \n",
    "                        # Process image\n",
    "                        image_outputs = model.image_model(image_inputs)\n",
    "                        # print(\"Image outputs shape:\", image_outputs.shape)\n",
    "                        \n",
    "                        \n",
    "                        del image_inputs\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                        # audio_inputs = batch['audio'].to(device)\n",
    "                        audio_inputs = batch['audio'].to(device).float()\n",
    "                        audio_outputs = model.audio_model(audio_inputs)\n",
    "                        del audio_inputs\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                        # Combine outputs\n",
    "                        combined = torch.cat((text_outputs, image_outputs, audio_outputs), dim=1)\n",
    "                        outputs = model.fusion_layer(combined)\n",
    "                        del combined, text_outputs, image_outputs, audio_outputs\n",
    "                        \n",
    "                        # Calculate loss\n",
    "                        labels = batch['label'].to(device).long()\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss = loss / accumulation_steps\n",
    "                    \n",
    "                    # Backward pass with gradient scaling\n",
    "                    scaler.scale(loss).backward()\n",
    "                    \n",
    "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                    \n",
    "                    train_loss += loss.item() * accumulation_steps\n",
    "                    \n",
    "                    # Clean up\n",
    "                    del outputs, loss, labels\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print('| WARNING: ran out of memory, skipping batch')\n",
    "                        torch.cuda.empty_cache()\n",
    "                        optimizer.zero_grad()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "            \n",
    "\n",
    "            # Rest of the training loop remains the same...\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            \n",
    "            with torch.no_grad():  # This prevents gradient calculation\n",
    "                for batch_idx, batch in enumerate(val_loader):\n",
    "                    try:\n",
    "                        # Process text\n",
    "                        text_inputs = {k: v.to(device) for k, v in batch['text'].items()}\n",
    "                        text_outputs = model.text_model(text_inputs)\n",
    "                        \n",
    "                        # Process image\n",
    "                        image_inputs = batch['image'].to(device).float()\n",
    "                        image_inputs = image_inputs.squeeze(1)\n",
    "                        image_outputs = model.image_model(image_inputs)\n",
    "                        \n",
    "                        # Process audio\n",
    "                        audio_inputs = batch['audio'].to(device).float()\n",
    "                        audio_outputs = model.audio_model(audio_inputs)\n",
    "                        \n",
    "                        # Combine outputs\n",
    "                        combined = torch.cat((text_outputs, image_outputs, audio_outputs), dim=1)\n",
    "                        outputs = model.fusion_layer(combined)\n",
    "                        \n",
    "                        # Calculate validation loss\n",
    "                        labels = batch['label'].to(device).long()\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        \n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        val_correct += (predicted == labels).sum().item()\n",
    "                        val_total += labels.size(0)\n",
    "\n",
    "                        \n",
    "                        # Clean up memory\n",
    "                        del outputs, text_outputs, image_outputs, audio_outputs, combined\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    except RuntimeError as e:\n",
    "                        if \"out of memory\" in str(e):\n",
    "                            print('| WARNING: ran out of memory during validation, skipping batch')\n",
    "                            torch.cuda.empty_cache()\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(f\"Runtime error in validation: {str(e)}\")\n",
    "                            raise\n",
    "                \n",
    "                # Calculate average validation loss\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                val_losses.append(avg_val_loss)\n",
    "                val_accuracy = val_correct / val_total if val_total > 0 else 0\n",
    "                \n",
    "                # Learning rate scheduling\n",
    "                scheduler.step(avg_val_loss)\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                learning_rates.append(current_lr)\n",
    "                \n",
    "                print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, LR = {current_lr}, Accuracy: {val_accuracy:.4f}')\n",
    "                \n",
    "                # Save best model\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': best_val_loss,\n",
    "                    }, 'best_multimodal_model.pth')\n",
    "            \n",
    "            # Clear cache after each epoch\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(f\"Training complete. Returning {len(train_losses)} epochs of data\")\n",
    "        return train_losses, val_losses, learning_rates\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training loop: {str(e)}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Even if there's an error, return what we have\n",
    "        return train_losses, val_losses, learning_rates\n",
    "    \n",
    "print(\"Training function ready!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83485f6-14d0-4d2a-bef8-b0b8dd4d60fa",
   "metadata": {},
   "source": [
    "Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59d6baab-0f79-46e9-ba29-4b3a528eb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main execution...\n",
      "Loading datasets...\n",
      "Loading train datasets...\n",
      "Loading text dataset...\n",
      "Loading image dataset...\n",
      "Loading audio dataset...\n",
      "All datasets loaded successfully!\n",
      "Loading test datasets...\n",
      "Loading text dataset...\n",
      "Loading image dataset...\n",
      "Loading audio dataset...\n",
      "All datasets loaded successfully!\n",
      "\n",
      "Initializing multimodal model...\n",
      "Loading pre-trained models...\n",
      "✅ Loading BERT model...\n",
      "✅ Loaded trained text model from best_bert_fake_news_detector\n",
      "✅ Loading LSTM model...\n",
      "✅ Loaded trained ViT model from image_model_results/best_image_model.pth\n",
      "✅ Loading trained audio model\n",
      "✅ Loaded trained audio model from best_lstm_fake_audio.pth\n",
      "✅ Loaded trained models\n",
      "\n",
      "GPU Memory Before Loading Model:\n",
      "Allocated: 4499.99 MB\n",
      "Cached: 5150.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10478/2717432483.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # Remove device_type parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Memory After Loading Model:\n",
      "Allocated: 5248.16 MB\n",
      "Cached: 5700.00 MB\n",
      "Starting training process...\n",
      "Initializing training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1582 [00:00<?, ?it/s]/tmp/ipykernel_10478/2717432483.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      " 34%|███▍      | 537/1582 [02:58<04:59,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image at index 2699: Image size (205728320 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1582/1582 [08:38<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1309, Val Loss = 0.2842, LR = 0.0001, Accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 813/1582 [04:09<02:59,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image at index 2699: Image size (205728320 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1582/1582 [08:15<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0537, Val Loss = 0.0131, LR = 0.0001, Accuracy: 0.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1268/1582 [06:37<01:20,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image at index 2699: Image size (205728320 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1582/1582 [08:13<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.1656, Val Loss = 0.0940, LR = 0.0001, Accuracy: 0.9821\n",
      "Training complete. Returning 3 epochs of data\n",
      "Training completed. Processing results...\n",
      "Training completed. Processing results...\n",
      "Number of epochs completed: 3\n",
      "Final training loss: 0.1656\n",
      "Final validation loss: 0.0940\n",
      "\n",
      "Training completed successfully!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " multimodal model PoC completed!!!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, recall_score, f1_score, precision_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm import create_model\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    # Set smaller batch size and enable memory optimization\n",
    "    BATCH_SIZE = 4  # Further reduced batch size\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    try:\n",
    "        # Create datasets with lazy loading\n",
    "        print(\"Loading datasets...\")\n",
    "        train_dataset = MultimodalDataset(split='train')\n",
    "        test_dataset = MultimodalDataset(split='test')\n",
    "        \n",
    "        # Create dataloaders with minimal memory footprint\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            num_workers=1,  # Reduced workers\n",
    "            pin_memory=False,  # Disabled pin_memory\n",
    "            prefetch_factor=1\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=1,\n",
    "            pin_memory=False,\n",
    "            prefetch_factor=1\n",
    "        )\n",
    "        \n",
    "        # Initialize model with memory optimization\n",
    "        print(\"\\nInitializing multimodal model...\")\n",
    "        model = MultimodalFakeNewsDetector()\n",
    "        \n",
    "        # Move model to CPU first\n",
    "        model = model.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Print memory status\n",
    "        print(\"\\nGPU Memory Before Loading Model:\")\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "        \n",
    "        # Move model to GPU in parts if needed\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            # Move individual components to GPU\n",
    "            model.text_model = model.text_model.to(device)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            model.image_model = model.image_model.to(device)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            model.audio_model = model.audio_model.to(device)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            model.fusion_layer = model.fusion_layer.to(device)\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"\\nGPU Memory After Loading Model:\")\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "        \n",
    "\n",
    "        # Train model with memory optimization\n",
    "        print(\"Starting training process...\")\n",
    "        results = train_multimodal_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            num_epochs=3,\n",
    "            learning_rate=0.0001\n",
    "        )\n",
    "\n",
    "        print(\"Training completed. Processing results...\")\n",
    "        # print(f\"Results type: {type(results)}\")\n",
    "        \n",
    "        if not isinstance(results, tuple):\n",
    "            raise ValueError(f\"Expected tuple from train_multimodal_model, got {type(results)}\")\n",
    "            \n",
    "        if len(results) != 3:\n",
    "            raise ValueError(f\"Expected 3 values, got {len(results)}\")\n",
    "            \n",
    "        train_losses, val_losses, learning_rates = results\n",
    "\n",
    "        print(\"Training completed. Processing results...\")\n",
    "        print(f\"Number of epochs completed: {len(train_losses)}\")\n",
    "        print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "        \n",
    "        return train_losses, val_losses, learning_rates  \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {str(e)}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Even if there's an error, return what we have\n",
    "        return train_losses, val_losses, learning_rates\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Starting main execution...\")\n",
    "        results = main()\n",
    "        \n",
    "        if not isinstance(results, tuple) or len(results) != 3:\n",
    "            raise ValueError(f\"Invalid results format: {type(results)}\")\n",
    "            \n",
    "        train_losses, val_losses, learning_rates = results\n",
    "        print(\"\\nTraining completed successfully!\")\n",
    "        \n",
    "        # Plot results\n",
    "        plot_training_curves(train_losses, val_losses, learning_rates)\n",
    "   \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {str(e)}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n multimodal model PoC completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df55e48-b1fe-410d-84a7-89d4e12d3d9b",
   "metadata": {},
   "source": [
    "### MultiModal Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda0247f-9893-4c34-bab9-8b441cb8d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained models...\n",
      "✅ Loading BERT model...\n",
      "✅ Loaded trained text model from best_bert_fake_news_detector\n",
      "✅ Loading LSTM model...\n",
      "✅ Loaded trained ViT model from image_model_results/best_image_model.pth\n",
      "✅ Loading trained audio model\n",
      "✅ Loaded trained audio model from best_lstm_fake_audio.pth\n",
      "✅ Loaded trained models\n",
      "Loading test datasets...\n",
      "Loading text dataset...\n",
      "Loading image dataset...\n",
      "Loading audio dataset...\n",
      "All datasets loaded successfully!\n",
      "Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 280/280 [01:19<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.9982\n",
      "Precision: 0.9982\n",
      "Recall: 0.9982\n",
      "F1 Score: 0.9982\n",
      "ROC AUC: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "=====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake     0.9981    0.9981    0.9981       521\n",
      "        Real     0.9983    0.9983    0.9983       596\n",
      "\n",
      "    accuracy                         0.9982      1117\n",
      "   macro avg     0.9982    0.9982    0.9982      1117\n",
      "weighted avg     0.9982    0.9982    0.9982      1117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multimodal_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the multimodal model's performance metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    print(\"Starting evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            try:\n",
    "                # Process text\n",
    "                text_inputs = {k: v.to(device) for k, v in batch['text'].items()}\n",
    "                text_outputs = model.text_model(text_inputs)\n",
    "                \n",
    "                # Process image\n",
    "                image_inputs = batch['image'].to(device).float()\n",
    "                image_inputs = image_inputs.squeeze(1)\n",
    "                image_outputs = model.image_model(image_inputs)\n",
    "                \n",
    "                # Process audio\n",
    "                audio_inputs = batch['audio'].to(device).float()\n",
    "                audio_outputs = model.audio_model(audio_inputs)\n",
    "                \n",
    "                # Combine outputs\n",
    "                combined = torch.cat((text_outputs, image_outputs, audio_outputs), dim=1)\n",
    "                outputs = model.fusion_layer(combined)\n",
    "                \n",
    "                # Get predictions\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                # Move to CPU and convert to numpy\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(batch['label'].cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                \n",
    "                # Clean up memory\n",
    "                del outputs, text_outputs, image_outputs, audio_outputs, combined\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error processing batch: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Generate classification report\n",
    "    target_names = ['Fake', 'Real']  \n",
    "    report = classification_report(\n",
    "        all_labels, \n",
    "        all_preds, \n",
    "        target_names=target_names,\n",
    "        digits=4,\n",
    "        output_dict=True\n",
    "    )    \n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(\"=====================\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': all_preds,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "# Usage example:\n",
    "def main():\n",
    "    # Initialize your model and test_loader here\n",
    "    model = MultimodalFakeNewsDetector()\n",
    "    test_dataset = MultimodalDataset(split='test')\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Load the best model weights\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint = torch.load('best_multimodal_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    results = evaluate_multimodal_model(model, test_loader, device)\n",
    "    \n",
    "    # Save results to file\n",
    "    with open('multimodal_evaluation_results.txt', 'w') as f:\n",
    "        f.write(\"Multimodal Model Evaluation Results\\n\")\n",
    "        f.write(\"==================================\\n\")\n",
    "        f.write(f\"📊 Accuracy: {results['accuracy']:.4f}\\n\")\n",
    "        f.write(f\"📊 Precision: {results['precision']:.4f}\\n\")\n",
    "        f.write(f\"📊 Recall: {results['recall']:.4f}\\n\")\n",
    "        f.write(f\"📊 F1 Score: {results['f1']:.4f}\\n\")\n",
    "        f.write(f\"📊 ROC AUC: {results['roc_auc']:.4f}\\n\")\n",
    "\n",
    "        \n",
    "    return train_losses, val_losses, learning_rates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff219d-ffea-48f9-a320-68f0b7ba630a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
